{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar_10_classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eswens13/deep_learning/blob/master/cifar_10_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6z5Ar347Yyn5",
        "colab_type": "text"
      },
      "source": [
        "# CIFAR-10 Classifier/Autoencoder\n",
        "\n",
        "This notebook is an exploratory exercise in convolutional neural networks.  I will build a classifier for the CIFAR-10 image set and play around with network architecture, hyperparameters, visualization techniques, etc. to get hands-on experience coding convolutional neural networks in TensorFlow.\n",
        "\n",
        "I will also explore the differences between a classifier and an auto-encoder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adTggxluwJQT",
        "colab_type": "text"
      },
      "source": [
        "## Define Network Architecture\n",
        "\n",
        "First, we have to define a network architecture.  The code in the cell below has comments explaining the architecture of each of the layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foT4cF9uqIpv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def forward_pass_core(img_batch, classes):\n",
        "  \"\"\"\n",
        "  Defines the neural network architecture for CIFAR-10 classification.\n",
        "  \n",
        "  Parameters:\n",
        "    - img_batch: A batch of images to classify, as a Tensor object.\n",
        "                 Shape: (N x 32 x 32 x 3)\n",
        "    - classes:   The labels for each image, as a Tensor object.\n",
        "                 Shape: (N, 10)\n",
        "  \"\"\"\n",
        "  [N, H, W, C] = img_batch.get_shape().as_list()\n",
        "  \n",
        "  # Convolutional Layer 1:\n",
        "  #    - Input shape: (N, 32, 32, 3)\n",
        "  #    - 16 3x3 filters\n",
        "  #    - Zero-pad input to keep same feature map dimensions\n",
        "  #    - ReLU activation\n",
        "  #    - Output shape: (N, 32, 32, 16)\n",
        "  with tf.variable_scope(\"conv1\", reuse=tf.AUTO_REUSE) as scope:\n",
        "    filter_shape_conv1 = (3, 3)\n",
        "    filters_conv1 = 64\n",
        "    w_conv1 = tf.get_variable(\"W\", \\\n",
        "                              [filter_shape_conv1[0], \\\n",
        "                                filter_shape_conv1[1], \\\n",
        "                                C, \\\n",
        "                                filters_conv1], \\\n",
        "                              initializer=tf.random_normal_initializer)\n",
        "    b_conv1 = tf.get_variable(\"b\", \\\n",
        "                              [filters_conv1], \\\n",
        "                              initializer=tf.zeros_initializer)\n",
        "    strides = [1, 1, 1, 1]\n",
        "    padding = \"SAME\"\n",
        "    \n",
        "    conv_conv1 = tf.nn.conv2d(img_batch, w_conv1, strides, padding)\n",
        "    out1 = tf.nn.relu(conv_conv1 + b_conv1, name=scope.name)\n",
        "    \n",
        "    # TODO: ReLU and max pooling commute so this should probably go before the\n",
        "    #       activation in order to save on computation (though this is minimal\n",
        "    #       right now).\n",
        "    # \n",
        "    # Max Pool Conv1\n",
        "    #     - 2x2 pool window\n",
        "    #     - 2x2 strides\n",
        "    #     - Output shape: (N, 16, 16, 16)\n",
        "    pooled_1 = tf.nn.pool(out1, [2,2], \"MAX\", \"VALID\", \\\n",
        "                          strides=[2,2], data_format=\"NHWC\")\n",
        "  \n",
        "  # Convolutional Layer 2:\n",
        "  #    - Input shape: (N, 16, 16, 16)\n",
        "  #    - 32 3x3 filters\n",
        "  #    - Zero pad input to keep same feature map dimensions\n",
        "  #    - ReLU activation\n",
        "  #    - Output shape: (N, 8, 8, 32)\n",
        "  with tf.variable_scope(\"conv2\", reuse=tf.AUTO_REUSE) as scope:\n",
        "    filter_shape_conv2 = (3, 3)\n",
        "    filters_conv2 = 128\n",
        "    w_conv2 = tf.get_variable(\"W\", \\\n",
        "                              [filter_shape_conv2[0], \\\n",
        "                                filter_shape_conv2[1], \\\n",
        "                                filters_conv1, \\\n",
        "                                filters_conv2], \\\n",
        "                              initializer=tf.random_normal_initializer)\n",
        "    b_conv2 = tf.get_variable(\"b\", \\\n",
        "                              [filters_conv2], \\\n",
        "                              initializer=tf.zeros_initializer)\n",
        "    strides = [1, 1, 1, 1]\n",
        "    padding = \"VALID\"\n",
        "    \n",
        "    conv_conv2 = tf.nn.conv2d(pooled_1, w_conv2, strides, padding)\n",
        "    out2 = tf.nn.relu(conv_conv2 + b_conv2, name=scope.name)\n",
        "    \n",
        "    # TODO: ReLU and max pooling commute so this should probably go before the\n",
        "    #       activation in order to save on computation (though this is minimal\n",
        "    #       right now).\n",
        "    # \n",
        "    # Max Pool Conv1\n",
        "    #     - 2x2 pool window\n",
        "    #     - 2x2 strides\n",
        "    #     - Output shape: (N, 8, 8, 32)\n",
        "    pooled_2 = tf.nn.pool(out2, [2,2], \"MAX\", \"VALID\", \\\n",
        "                          strides=[2,2], data_format=\"NHWC\")\n",
        "    \n",
        "    # Since this is the last convolutional layer, we need to \"flatten\" the\n",
        "    # output into a one dimensional vector (well, really a one-dimensional\n",
        "    # vector per input image).\n",
        "    flat_out = tf.reshape(pooled_2, [N, -1])\n",
        "    neurons_flat = flat_out.get_shape().as_list()[1]\n",
        "  \n",
        "  # Convolutional Layer 3:\n",
        "  #    - Input shape: (N, 30, 30, 32)\n",
        "  #    - 64 5x5 filters\n",
        "  #    - Lose two pixels off each side because of convolution.\n",
        "  #    - ReLU activation\n",
        "  #    - Output shape: (N, 26, 26, 64)\n",
        "  '''with tf.variable_scope(\"conv3\", reuse=tf.AUTO_REUSE) as scope:\n",
        "    filter_shape_conv3 = (5, 5)\n",
        "    filters_conv3 = 64\n",
        "    w_conv3 = tf.get_variable(\"W\", \\\n",
        "                              [filter_shape_conv3[0], \\\n",
        "                                filter_shape_conv3[1], \\\n",
        "                                filters_conv2, \\\n",
        "                                filters_conv3], \\\n",
        "                              initializer=tf.random_normal_initializer)\n",
        "    b_conv3 = tf.get_variable(\"b\", \\\n",
        "                              [filters_conv3], \\\n",
        "                              initializer=tf.zeros_initializer)\n",
        "    strides = [1, 1, 1, 1]\n",
        "    padding = \"VALID\"\n",
        "    \n",
        "    conv_conv3 = tf.nn.conv2d(out2, w_conv3, strides, padding)\n",
        "    out3 = tf.nn.relu(conv_conv3 + b_conv3, name=scope.name)\n",
        "  \n",
        "    # Since this is the last convolutional layer, we need to \"flatten\" the\n",
        "    # output into a one dimensional vector (well, really a one-dimensional\n",
        "    # vector per input image).\n",
        "    flat_out = tf.reshape(out3, [N, -1])\n",
        "    neurons_flat = flat_out.get_shape().as_list()[1]'''\n",
        "  \n",
        "  # Dense Layer 1:\n",
        "  #    - Input shape: (N, (8 * 8 * 64))\n",
        "  #    - Neurons: 512\n",
        "  #    - ReLU activation\n",
        "  #    - Ouput shape: (N, 512)\n",
        "  with tf.variable_scope(\"dense1\", reuse=tf.AUTO_REUSE) as scope:\n",
        "    neurons_dense1 = 512\n",
        "    w_dense1 = tf.get_variable(\"W\", \\\n",
        "                               [neurons_flat, neurons_dense1], \\\n",
        "                               initializer=tf.random_normal_initializer)\n",
        "    b_dense1 = tf.get_variable(\"b\", \\\n",
        "                               [neurons_dense1], \\\n",
        "                               initializer=tf.zeros_initializer)\n",
        "    mul_dense1 = tf.matmul(flat_out, w_dense1)\n",
        "    out_dense1 = tf.nn.relu(mul_dense1 + b_dense1, name=scope.name)\n",
        "  \n",
        "  # Dense Layer 2:\n",
        "  #    - Input shape: (N, 512)\n",
        "  #    - Neurons: 128\n",
        "  #    - ReLU activation\n",
        "  #    - Ouput shape: (N, 128)\n",
        "  with tf.variable_scope(\"dense2\", reuse=tf.AUTO_REUSE) as scope:\n",
        "    neurons_dense2 = 128\n",
        "    w_dense2 = tf.get_variable(\"W\", \\\n",
        "                               [neurons_dense1, neurons_dense2], \\\n",
        "                               initializer=tf.random_normal_initializer)\n",
        "    b_dense2 = tf.get_variable(\"b\", \\\n",
        "                                [neurons_dense2], \\\n",
        "                                initializer=tf.zeros_initializer)\n",
        "    mul_dense2 = tf.matmul(out_dense1, w_dense2)\n",
        "    out_dense2 = tf.nn.relu(mul_dense2 + b_dense2, name=scope.name)\n",
        "    \n",
        "  with tf.variable_scope(\"dense3\", reuse=tf.AUTO_REUSE) as scope:\n",
        "    n_classes = 10\n",
        "    w_dense3 = tf.get_variable(\"W\", \\\n",
        "                               [neurons_dense2, n_classes], \\\n",
        "                               initializer=tf.random_normal_initializer)\n",
        "    b_dense3 = tf.get_variable(\"b\", \\\n",
        "                                [n_classes], \\\n",
        "                                initializer=tf.zeros_initializer)\n",
        "    mul_dense3 = tf.matmul(out_dense2, w_dense3)\n",
        "    out_dense3 = mul_dense3 + b_dense3\n",
        "  \n",
        "  return out_dense3\n",
        "\n",
        "def forward_pass_train(img_batch, classes):\n",
        "  print(\"forward_pass_train\")\n",
        "  \n",
        "  # Get the output from the core of the network.\n",
        "  out_dense3 = forward_pass_core(img_batch, classes)\n",
        "  \n",
        "  # Add a Softmax layer with the cross entropy loss.\n",
        "  with tf.variable_scope(\"softmax_train\") as scope:\n",
        "    # The reduce_mean takes the mean in a given axis, thereby reducing the\n",
        "    # the dimensions of the tensor. If no axis is given, it takes the mean of\n",
        "    # the entire tensor.\n",
        "    #\n",
        "    # The softmax_cross_entropy_with_logits_v2 function calculates the softmax\n",
        "    # cross entropy loss without requiring us to convert the outputs of the last\n",
        "    # dense layer into probabilities first. (The 'logits' are raw outputs of the\n",
        "    # aforementioned outputs.)\n",
        "    softmax_out = tf.nn.softmax_cross_entropy_with_logits_v2( \\\n",
        "                      labels=tf.stop_gradient(classes), logits=out_dense3)\n",
        "\n",
        "    # Calculate the accuracy of the network on the batch of training data.\n",
        "    predictions = tf.argmax(out_dense3, axis=1)\n",
        "    ground_truth = tf.argmax(classes, axis=1)\n",
        "    acc = tf.metrics.accuracy(ground_truth, predictions) # Using this function\n",
        "                                                         # requires initializing\n",
        "                                                         # local variables as\n",
        "                                                         # well as global.\n",
        "    \n",
        "    # Calculate the loss on the batch of training data.\n",
        "    loss = tf.reduce_mean(softmax_out)\n",
        "  \n",
        "  return loss, acc\n",
        "\n",
        "def forward_pass_test(img_batch, classes):\n",
        "  print(\"forward_pass_test\")\n",
        "  \n",
        "  # Get the output from the core of the network.\n",
        "  out_dense3 = forward_pass_core(img_batch, classes)\n",
        "  \n",
        "  # Add a Softmax layer to get the core.\n",
        "  with tf.variable_scope(\"softmax_test\") as scope:\n",
        "    # The reduce_mean takes the mean in a given axis, thereby reducing the\n",
        "    # the dimensions of the tensor. If no axis is given, it takes the mean of\n",
        "    # the entire tensor.\n",
        "    #\n",
        "    # The softmax_cross_entropy_with_logits_v2 function calculates the softmax\n",
        "    # cross entropy loss without requiring us to convert the outputs of the last\n",
        "    # dense layer into probabilities first. (The 'logits' are raw outputs of the\n",
        "    # aforementioned outputs.)\n",
        "    softmax_out = tf.nn.softmax(logits=out_dense3)\n",
        "  \n",
        "  return softmax_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYdNDESBQPqa",
        "colab_type": "text"
      },
      "source": [
        "## Training Setup\n",
        "\n",
        "Now that we've defined a network architecture, we need to set up a training loop to map how the network will be updated.  We need to choose an optimizer and set up backpropagation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rU1UppagQA_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def train_batch(img_batch, labels, optimizer):\n",
        "  \"\"\"\n",
        "  Trains the network (forward pass followed by backpropagation) on a batch of\n",
        "  images.\n",
        "  \n",
        "  Parameters:\n",
        "    - img_batch: A batch of input images, as a Tensor object.\n",
        "                 Shape: (N, H, W, C)\n",
        "    - labels:    The labels for each input image in the batch, as a Tensor.\n",
        "                 Shape: (N, 10)\n",
        "    - optimizer: A TF Optimizer object that performs the backpropagation.\n",
        "  \"\"\"\n",
        "  loss, acc = forward_pass_train(img_batch, labels)\n",
        "  opt = optimizer.minimize(loss)\n",
        "  return loss, opt, acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8scLrYSed0AU",
        "colab_type": "text"
      },
      "source": [
        "Here, we simulate a single batch of data just to verify that forward and backward pass run without issue."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jGb86smxLMp",
        "colab_type": "code",
        "outputId": "490acdf8-58bc-40aa-caff-83c7e364d516",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Reset the graph so we don't have variable collisions when we re-run.\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# Simulate a batch of 32 images (each 32 x 32 pixels RBG)\n",
        "input_image = np.zeros((32, 32, 32, 3))\n",
        "\n",
        "# Simulate a batch of labels for the input images.\n",
        "input_labels = np.zeros((32, 10))\n",
        "for i in range(input_labels.shape[0]):\n",
        "  input_labels[i][i % 10] = 1\n",
        "\n",
        "# Create a placeholder for the input tensor (to be passed to the model).\n",
        "img = tf.placeholder(tf.float32, shape=input_image.shape)\n",
        "\n",
        "# Create a placeholder for the corresponding labels.\n",
        "img_labels = tf.placeholder(tf.float32, shape=input_labels.shape)\n",
        "\n",
        "# Create an optimizer that will manage the backpropagation.\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=1e-3)\n",
        "\n",
        "# Run a single training loop.\n",
        "loss, backprop, acc = train_batch(img, img_labels, optimizer)\n",
        "\n",
        "# Create the TF session and run the graph.\n",
        "with tf.Session() as sess:\n",
        "  # Initialize all the variables according to their initializers.\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  sess.run(tf.local_variables_initializer())\n",
        "\n",
        "  # This call starts the chain of operations in the computation graph created\n",
        "  # above.\n",
        "  loss_output = sess.run(loss, feed_dict={img: input_image, \\\n",
        "                                          img_labels: input_labels})\n",
        "  \n",
        "  opt_output = sess.run(backprop, feed_dict={img: input_image, \\\n",
        "                                             img_labels: input_labels})\n",
        "  \n",
        "  stuff = sess.run(acc, feed_dict={img: input_image, \\\n",
        "                                   img_labels: input_labels})\n",
        "  \n",
        "  print(\"Output: {}\".format(loss_output))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "forward_pass_train\n",
            "Output: 2.3025851249694824\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw4ep02TeBSX",
        "colab_type": "text"
      },
      "source": [
        "## Bring in Data\n",
        "\n",
        "In order to actually train the model, we need to bring in actual data.  Download the CIFAR-10 dataset and get it into a format that we can use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oswKFhE1LjQQ",
        "colab_type": "code",
        "outputId": "5b8403fd-1655-4414-8d2f-e9ff6742e33b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# I'm cheating and using Keras to import the dataset without having to do a lot\n",
        "# of processing myself.\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Change the labels to one-hot vectors.\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# Examine what the data looks like.\n",
        "print(\"X_train shape: {}\".format(X_train.shape))\n",
        "print(\"y_train shape: {}\".format(y_train.shape))\n",
        "print(\"X_test shape: {}\".format(X_test.shape))\n",
        "print(\"y_test shape: {}\".format(y_test.shape))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape: (50000, 32, 32, 3)\n",
            "y_train shape: (50000, 10)\n",
            "X_test shape: (10000, 32, 32, 3)\n",
            "y_test shape: (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbLmbPTafmLK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training_loop(X, y, val_X, val_y, num_epochs=10, batch_size=128, learning_rate=1e-3):\n",
        "  \"\"\"\n",
        "  Trains a CNN on the CIFAR-10 dataset.\n",
        "  \n",
        "  Parameters:\n",
        "    - X:             The set of training samples to choose from. \n",
        "    - num_epochs:    The number of batches to process.\n",
        "    - num_samples:   The total number of samples to choose from.\n",
        "    - batch_size:    The number of samples in a training batch.\n",
        "    - learning_rate: The learning rate to use during backpropagation.\n",
        "  \"\"\"\n",
        "  num_samples = X.shape[0]\n",
        "  \n",
        "  # Reset the graph so we don't have variable collisions when we re-run.\n",
        "  tf.reset_default_graph()\n",
        "\n",
        "  # Create a placeholder for the input tensor (to be passed to the model).\n",
        "  img = tf.placeholder(tf.float32, \\\n",
        "                       shape=(batch_size, X.shape[1], X.shape[2], X.shape[3]))\n",
        "\n",
        "  # Create a placeholder for the corresponding labels.\n",
        "  img_labels = tf.placeholder(tf.float32, shape=(batch_size, y.shape[1]))\n",
        "\n",
        "  # Create an optimizer that will manage the backpropagation.\n",
        "  optimizer = tf.train.AdamOptimizer(learning_rate=1e-3)\n",
        "\n",
        "  # Run a single training loop.\n",
        "  loss, backprop, batch_acc = train_batch(img, img_labels, optimizer)\n",
        "  \n",
        "  # Create an operation for the test time forward pass.\n",
        "  test_op = forward_pass_test(img, img_labels)\n",
        "  \n",
        "  # Create a vector for the losses from each epoch.\n",
        "  loss_history = []\n",
        "  \n",
        "  # Create a vector for the training accuracy history.\n",
        "  train_acc_history = []\n",
        "  \n",
        "  # Create a vector for the validation accuracy history.\n",
        "  val_acc_history = []\n",
        "\n",
        "  # Create the TF session and run the graph.\n",
        "  with tf.Session() as sess:\n",
        "    # Initialize all the variables according to their initializers.\n",
        "    sess.run(tf.global_variables_initializer())   \n",
        "    sess.run(tf.local_variables_initializer())\n",
        "      \n",
        "    for i in range(num_epochs):\n",
        "      # Randomly select a batch of images from the training set.\n",
        "      inds = np.random.randint(0, num_samples, batch_size)\n",
        "      tr_batch = X[inds]\n",
        "      tr_batch_labels = y[inds]\n",
        "      \n",
        "      # Randomly select a batch of images from the validation set.\n",
        "      val_inds = np.random.randint(0, val_X.shape[0], batch_size)\n",
        "      test_batch = val_X[val_inds]\n",
        "      test_batch_labels = val_y[val_inds]\n",
        "      \n",
        "      # Get the loss using the current weights in the graph. This call starts\n",
        "      # the chain of operations in the computation graph created above.\n",
        "      epoch_loss = sess.run(loss, feed_dict={img: tr_batch, \\\n",
        "                                             img_labels: tr_batch_labels})\n",
        "      \n",
        "      # Get the accuracy on the batch of training samples.\n",
        "      # TODO: Why does train_acc contain two elements?\n",
        "      train_acc = sess.run(batch_acc, feed_dict={img: tr_batch, \\\n",
        "                                                 img_labels: tr_batch_labels})\n",
        "      train_acc_history.append(train_acc[0])\n",
        "      \n",
        "      # TODO: Doesn't this call the forward pass and the backward pass? So am I\n",
        "      #       going through the forward pass twice each epoch?\n",
        "      # Run backpropagation on the graph.\n",
        "      sess.run(backprop, feed_dict={img: tr_batch, \\\n",
        "                                    img_labels: tr_batch_labels})\n",
        "      \n",
        "      # Keep track of the loss.\n",
        "      loss_history.append(epoch_loss)\n",
        "    \n",
        "      # Run the forward pass only to get the accuracy of the trained network.\n",
        "      scores = sess.run(test_op, feed_dict={img: test_batch, \\\n",
        "                                            img_labels: test_batch_labels})\n",
        "      \n",
        "      # TODO: In the first place, the accuracy never gets very high, maybe 30%.\n",
        "      #       Secondly, there is a plateau and then a dip in the accuracy over\n",
        "      #       time. Things to try:\n",
        "      #         - Use dropout (or other form of regularization)\n",
        "      #         - Add max pooling layers after convolution\n",
        "      #         - Mess with kernel sizes, number of feature maps\n",
        "      #         - Possibly reduce the size of the network?\n",
        "      #         - Hyperparameters? (learning rate, etc.)\n",
        "      num_correct = scores.shape[0]\n",
        "      for i in range(scores.shape[0]):\n",
        "        if np.argmax(scores[i]) != np.argmax(test_batch_labels[i]):\n",
        "          num_correct -= 1\n",
        "  \n",
        "      acc = float(num_correct) / float(len(scores))\n",
        "      val_acc_history.append(acc)\n",
        "\n",
        "  # Plot the loss over the whole training episode.\n",
        "  np_thing = np.array(train_acc_history)\n",
        "  font_dict = { 'fontweight' : 'bold' }\n",
        "  plt.title(\"Training Loss\", fontdict=font_dict)\n",
        "  plt.plot(loss_history)\n",
        "  plt.figure()\n",
        "  plt.title(\"Training Accuracy History\", fontdict=font_dict)\n",
        "  plt.plot(train_acc_history)\n",
        "  plt.figure()\n",
        "  plt.title(\"Validation Accuracy History\", fontdict=font_dict)\n",
        "  plt.plot(val_acc_history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGsrpneaF7Gb",
        "colab_type": "text"
      },
      "source": [
        "## Run Training\n",
        "\n",
        "Run the training loop for 100 batches of images (happens fairly fast) and investigate the effectiveness of the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCSUGYpZk-Cp",
        "colab_type": "code",
        "outputId": "df2c1d10-d227-4df9-e427-0bcbc847b461",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 843
        }
      },
      "source": [
        "training_loop(X_train, y_train, X_test, y_test, num_epochs=2000)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "forward_pass_train\n",
            "forward_pass_test\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFO4iImlI4S4ikoYU7iIiaUjhLiKShv4/ZyXahQ/+ASEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFKLQFxFJIQp9EZEU8v8Ba25vVt6nkU4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQpS+IAhCJeL/AXthXgV3btdyAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ky7MjyB3H9s5",
        "colab_type": "text"
      },
      "source": [
        "## Validate the Network\n",
        "\n",
        "Run the network against the validation data set to evaluate the classification effectiveness."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBVXlbJqIGoZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Need to use a Saver to save the network weights so that we can validate\n",
        "#       it in a separate session.\n",
        "def validate(X, y):\n",
        "  \"\"\"\n",
        "  Validates a CNN trained on the CIFAR-10 dataset.\n",
        "  \n",
        "  Parameters:\n",
        "    - X:    The set of validation samples. \n",
        "    - y:    The ground truth labels for the samples.\n",
        "  \"\"\"\n",
        "\n",
        "  # Create a placeholder for the input tensor (to be passed to the model).\n",
        "  img = tf.placeholder(tf.float32, shape=X.shape)\n",
        "\n",
        "  # Create a placeholder for the corresponding labels.\n",
        "  img_labels = tf.placeholder(tf.float32, shape=y.shape)\n",
        "  \n",
        "  # Create an operation for the test time forward pass.\n",
        "  test_op = forward_pass_test(img, img_labels)\n",
        "\n",
        "  # Create the TF session and run the graph.\n",
        "  with tf.Session() as sess:\n",
        "    # Create a batch of the same size as the network.\n",
        "    batch_size = 128\n",
        "    inds = np.random.randint(0, X.shape[0], batch_size)\n",
        "    batch = X[inds]\n",
        "    batch_labels = y[inds]\n",
        "    \n",
        "    # Get the loss using the current weights in the graph. This call starts\n",
        "    # the chain of operations in the computation graph created above.\n",
        "    labels = sess.run(test_op, feed_dict={img: X, img_labels: y})\n",
        "    \n",
        "    print(\"Output Shape: {}\".format(labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE_JVXrOat0Y",
        "colab_type": "code",
        "outputId": "168cc1d2-161f-473a-b170-d90a2c99dd72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2792
        }
      },
      "source": [
        "validate(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "forward_pass_test\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FailedPreconditionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value dense3/b\n\t [[{{node dense3/b/read}}]]\n\t [[{{node softmax_test/Softmax}}]]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-1fa46a04e996>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-69f8fc4da788>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Get the loss using the current weights in the graph. This call starts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# the chain of operations in the computation graph created above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Output Shape: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value dense3/b\n\t [[node dense3/b/read (defined at <ipython-input-17-c2307d23d0a0>:99) ]]\n\t [[node softmax_test/Softmax (defined at <ipython-input-17-c2307d23d0a0>:141) ]]\n\nCaused by op 'dense3/b/read', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-22-abb383ed79af>\", line 1, in <module>\n    training_loop(X_train, y_train, num_epochs=100)\n  File \"<ipython-input-21-a8da4239d22c>\", line 27, in training_loop\n    loss, backprop = train_batch(img, img_labels, optimizer)\n  File \"<ipython-input-18-6fa18980660b>\", line 15, in train_batch\n    loss = forward_pass_train(img_batch, labels)\n  File \"<ipython-input-17-c2307d23d0a0>\", line 109, in forward_pass_train\n    out_dense3 = forward_pass_core(img_batch, classes)\n  File \"<ipython-input-17-c2307d23d0a0>\", line 99, in forward_pass_core\n    b_dense3 = tf.get_variable(\"b\",                                 [n_classes],                                 initializer=tf.zeros_initializer)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1479, in get_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1220, in get_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 547, in get_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 499, in _true_getter\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 911, in _get_single_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 213, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 176, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 155, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2495, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 217, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 1395, in __init__\n    constraint=constraint)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 1557, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\", line 180, in wrapper\n    return target(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\", line 81, in identity\n    ret = gen_array_ops.identity(input, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 3890, in identity\n    \"Identity\", input=input, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value dense3/b\n\t [[node dense3/b/read (defined at <ipython-input-17-c2307d23d0a0>:99) ]]\n\t [[node softmax_test/Softmax (defined at <ipython-input-17-c2307d23d0a0>:141) ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSjbNFKeqbIQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "6fad8206-6360-4392-bb51-3fa04ee6cc2b"
      },
      "source": [
        "# Pooling Test\n",
        "\n",
        "# Create some small dimensional \"image\" with each pixel as a random number\n",
        "# between one and ten that will be easy to print and see the difference between\n",
        "# original and pooled versions.\n",
        "# \n",
        "# Note that I've put batch size, then channels first here (that way it displays\n",
        "# better).\n",
        "test_img = np.random.randint(10, size=(1,3,4,6))\n",
        "print(\"Test Image:\\n{}\".format(test_img))\n",
        "\n",
        "test_input_img = tf.placeholder(tf.float32, shape=test_img.shape)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  pool_window = [2,2]\n",
        "  pool_type = \"MAX\"\n",
        "  pad_type = \"VALID\" # This means we're not zero padding to keep dimensions the\n",
        "                     # same. In other words, we're downsampling.\n",
        "  data_format_str = \"NCHW\"  # N - batch size, C - channels, H - height, W - width\n",
        "  stride_val = [2,2] # Don't overlap pooling windows.\n",
        "  pooled = sess.run(tf.nn.pool(test_input_img, \\\n",
        "                               pool_window, \\\n",
        "                               pool_type, \\\n",
        "                               pad_type, \\\n",
        "                               strides=stride_val, \\\n",
        "                               data_format=data_format_str), \\\n",
        "                    feed_dict={test_input_img: test_img})\n",
        "  \n",
        "  print(\"Pooled:\\n{}\".format(pooled))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Image:\n",
            "[[[[0 3 5 1 6 7]\n",
            "   [3 5 5 0 4 3]\n",
            "   [9 8 6 6 8 5]\n",
            "   [4 2 9 4 5 6]]\n",
            "\n",
            "  [[5 7 9 6 1 3]\n",
            "   [4 5 0 9 5 0]\n",
            "   [7 7 8 2 7 4]\n",
            "   [3 4 1 4 4 8]]\n",
            "\n",
            "  [[3 7 4 3 0 9]\n",
            "   [2 5 0 9 3 6]\n",
            "   [7 6 1 1 1 0]\n",
            "   [3 3 2 7 8 2]]]]\n",
            "Pooled:\n",
            "[[[[5. 5. 7.]\n",
            "   [9. 9. 8.]]\n",
            "\n",
            "  [[7. 9. 5.]\n",
            "   [7. 8. 8.]]\n",
            "\n",
            "  [[7. 9. 9.]\n",
            "   [7. 7. 8.]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aH9pMCtmvqq",
        "colab_type": "text"
      },
      "source": [
        "# What Did I Learn?\n",
        "\n",
        "At first, I had three convolutional layers with no pooling between them.  Training accuracy goes up to about 25% after about 400 epochs (batch size 128) and then takes a dive.  Validation accuracy does about the same, but it is much more volatile.\n",
        "\n",
        "Added pooling after each convolutional layer and took out the third convolutional layer because, after the second convolutional layer, the feature maps were only 8x8.  Slight improvement in training and validation accuracy (~30-35%), but that's still not very good at all.\n",
        "\n",
        "Doubled the number of feature maps per convolutional layer.  Again, slight increase in accuracy.\n",
        "\n",
        "Doubled the number of feature maps again for each convolutional layer.  About the same.\n",
        "\n",
        "Decreased the learning rate by an order of magnitude.  Not sure if it was effective or not.\n",
        "\n",
        "I think I need to check my accuracy calculation to make sure I'm not using it incorrectly.  Also, compare against known successful CIFAR-10 classifiers."
      ]
    }
  ]
}