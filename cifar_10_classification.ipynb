{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar_10_classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eswens13/deep_learning/blob/master/cifar_10_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "6z5Ar347Yyn5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CIFAR-10 Classifier/Autoencoder\n",
        "\n",
        "This notebook is an exploratory exercise in convolutional neural networks.  I will build a classifier for the CIFAR-10 image set and play around with network architecture, hyperparameters, visualization techniques, etc. to get hands-on experience coding convolutional neural networks in TensorFlow.\n",
        "\n",
        "I will also explore the differences between a classifier and an auto-encoder."
      ]
    },
    {
      "metadata": {
        "id": "adTggxluwJQT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define Network Architecture\n",
        "\n",
        "First, we have to define a network architecture.  The code in the cell below has comments explaining the architecture of each of the layers."
      ]
    },
    {
      "metadata": {
        "id": "foT4cF9uqIpv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def create_model(img_batch, classes):\n",
        "  \"\"\"\n",
        "  Defines the neural network architecture for CIFAR-10 classification.\n",
        "  \n",
        "  Parameters:\n",
        "    - img_batch: A batch of images to classify, as a Tensor object.\n",
        "                 Shape: (N x 32 x 32 x 3)\n",
        "    - classes:   The labels for each image, as a Tensor object.\n",
        "                 Shape: (N, 10)\n",
        "  \"\"\"\n",
        "  [N, H, W, C] = img_batch.get_shape().as_list()\n",
        "  \n",
        "  # Convolutional Layer 1:\n",
        "  #    - Input shape: (N, 32, 32, 3)\n",
        "  #    - 16 3x3 filters\n",
        "  #    - Zero-pad input to keep same feature map dimensions\n",
        "  #    - ReLU activation\n",
        "  #    - Output shape: (N, 32, 32, 16)\n",
        "  with tf.variable_scope(\"conv1\") as scope:\n",
        "    filter_shape_conv1 = (3, 3)\n",
        "    filters_conv1 = 16\n",
        "    w_conv1 = tf.get_variable(\"W\", \\\n",
        "                              [filter_shape_conv1[0], \\\n",
        "                                filter_shape_conv1[1], \\\n",
        "                                C, \\\n",
        "                                filters_conv1], \\\n",
        "                              initializer=tf.random_normal_initializer)\n",
        "    b_conv1 = tf.get_variable(\"b\", \\\n",
        "                              [filters_conv1], \\\n",
        "                              initializer=tf.zeros_initializer)\n",
        "    strides = [1, 1, 1, 1]\n",
        "    padding = \"SAME\"\n",
        "    \n",
        "    conv_conv1 = tf.nn.conv2d(img_batch, w_conv1, strides, padding)\n",
        "    out1 = tf.nn.relu(conv_conv1 + b_conv1, name=scope.name)\n",
        "  \n",
        "  # Convolutional Layer 2:\n",
        "  #    - Input shape: (N, 32, 32, 16)\n",
        "  #    - 32 3x3 filters\n",
        "  #    - Lose a pixel off each side because of convolution.\n",
        "  #    - ReLU activation\n",
        "  #    - Output shape: (N, 30, 30, 32)\n",
        "  with tf.variable_scope(\"conv2\") as scope:\n",
        "    filter_shape_conv2 = (3, 3)\n",
        "    filters_conv2 = 32\n",
        "    w_conv2 = tf.get_variable(\"W\", \\\n",
        "                              [filter_shape_conv2[0], \\\n",
        "                                filter_shape_conv2[1], \\\n",
        "                                filters_conv1, \\\n",
        "                                filters_conv2], \\\n",
        "                              initializer=tf.random_normal_initializer)\n",
        "    b_conv2 = tf.get_variable(\"b\", \\\n",
        "                              [filters_conv2], \\\n",
        "                              initializer=tf.zeros_initializer)\n",
        "    strides = [1, 1, 1, 1]\n",
        "    padding = \"VALID\"\n",
        "    \n",
        "    conv_conv2 = tf.nn.conv2d(out1, w_conv2, strides, padding)\n",
        "    out2 = tf.nn.relu(conv_conv2 + b_conv2, name=scope.name)\n",
        "  \n",
        "  # Convolutional Layer 3:\n",
        "  #    - Input shape: (N, 30, 30, 32)\n",
        "  #    - 64 5x5 filters\n",
        "  #    - Lose two pixels off each side because of convolution.\n",
        "  #    - ReLU activation\n",
        "  #    - Output shape: (N, 26, 26, 64)\n",
        "  with tf.variable_scope(\"conv3\") as scope:\n",
        "    filter_shape_conv3 = (5, 5)\n",
        "    filters_conv3 = 64\n",
        "    w_conv3 = tf.get_variable(\"W\", \\\n",
        "                              [filter_shape_conv3[0], \\\n",
        "                                filter_shape_conv3[1], \\\n",
        "                                filters_conv2, \\\n",
        "                                filters_conv3], \\\n",
        "                              initializer=tf.random_normal_initializer)\n",
        "    b_conv3 = tf.get_variable(\"b\", \\\n",
        "                              [filters_conv3], \\\n",
        "                              initializer=tf.zeros_initializer)\n",
        "    strides = [1, 1, 1, 1]\n",
        "    padding = \"VALID\"\n",
        "    \n",
        "    conv_conv3 = tf.nn.conv2d(out2, w_conv3, strides, padding)\n",
        "    out3 = tf.nn.relu(conv_conv3 + b_conv3, name=scope.name)\n",
        "  \n",
        "    # Since this is the last convolutional layer, we need to \"flatten\" the\n",
        "    # output into a one dimensional vector (well, really a one-dimensional\n",
        "    # vector per input image).\n",
        "    flat_out = tf.reshape(out3, [N, -1])\n",
        "    neurons_flat = flat_out.get_shape().as_list()[1]\n",
        "  \n",
        "  # Dense Layer 1:\n",
        "  #    - Input shape: (N, (26 * 26 * 64))\n",
        "  #    - Neurons: 512\n",
        "  #    - ReLU activation\n",
        "  #    - Ouput shape: (N, 512)\n",
        "  with tf.variable_scope(\"dense1\") as scope:\n",
        "    neurons_dense1 = 512\n",
        "    w_dense1 = tf.get_variable(\"W\", \\\n",
        "                               [neurons_flat, neurons_dense1], \\\n",
        "                               initializer=tf.random_normal_initializer)\n",
        "    b_dense1 = tf.get_variable(\"b\", \\\n",
        "                               [neurons_dense1], \\\n",
        "                               initializer=tf.zeros_initializer)\n",
        "    mul_dense1 = tf.matmul(flat_out, w_dense1)\n",
        "    out_dense1 = tf.nn.relu(mul_dense1 + b_dense1, name=scope.name)\n",
        "  \n",
        "  # Dense Layer 2:\n",
        "  #    - Input shape: (N, 512)\n",
        "  #    - Neurons: 128\n",
        "  #    - ReLU activation\n",
        "  #    - Ouput shape: (N, 128)\n",
        "  with tf.variable_scope(\"dense2\") as scope:\n",
        "    neurons_dense2 = 128\n",
        "    w_dense2 = tf.get_variable(\"W\", \\\n",
        "                               [neurons_dense1, neurons_dense2], \\\n",
        "                               initializer=tf.random_normal_initializer)\n",
        "    b_dense2 = tf.get_variable(\"b\", \\\n",
        "                                [neurons_dense2], \\\n",
        "                                initializer=tf.zeros_initializer)\n",
        "    mul_dense2 = tf.matmul(out_dense1, w_dense2)\n",
        "    out_dense2 = tf.nn.relu(mul_dense2 + b_dense2, name=scope.name)\n",
        "    \n",
        "  with tf.variable_scope(\"dense3\") as scope:\n",
        "    n_classes = 10\n",
        "    w_dense3 = tf.get_variable(\"W\", \\\n",
        "                               [neurons_dense2, n_classes], \\\n",
        "                               initializer=tf.random_normal_initializer)\n",
        "    b_dense3 = tf.get_variable(\"b\", \\\n",
        "                                [n_classes], \\\n",
        "                                initializer=tf.zeros_initializer)\n",
        "    mul_dense3 = tf.matmul(out_dense2, w_dense3)\n",
        "    out_dense3 = mul_dense3 + b_dense3\n",
        "  \n",
        "  # Softmax layer.\n",
        "  with tf.variable_scope(\"softmax\") as scope:\n",
        "    # The reduce_mean takes the mean in a given axis, thereby reducing the\n",
        "    # the dimensions of the tensor. If no axis is given, it takes the mean of\n",
        "    # the entire tensor.\n",
        "    #\n",
        "    # The softmax_cross_entropy_with_logits_v2 function calculates the softmax\n",
        "    # cross entropy loss without requiring us to convert the outputs of the last\n",
        "    # dense layer into probabilities first. (The 'logits' are raw outputs of the\n",
        "    # aforementioned outputs.)\n",
        "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2( \\\n",
        "                          labels=classes, logits=out_dense3))\n",
        "  \n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oYdNDESBQPqa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training Setup\n",
        "\n",
        "Now that we've defined a network architecture, we need to set up a training loop to map how the network will be updated.  We need to choose an optimizer and set up backpropagation."
      ]
    },
    {
      "metadata": {
        "id": "rU1UppagQA_n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_batch(img_batch, labels, optimizer):\n",
        "  \"\"\"\n",
        "  Trains the network (forward pass followed by backpropagation) on a batch of\n",
        "  images.\n",
        "  \n",
        "  Parameters:\n",
        "    - img_batch: A batch of input images, as a Tensor object.\n",
        "                 Shape: (N, H, W, C)\n",
        "    - labels:    The labels for each input image in the batch, as a Tensor.\n",
        "                 Shape: (N, 10)\n",
        "    - optimizer: A TF Optimizer object that performs the backpropagation.\n",
        "  \"\"\"\n",
        "  loss = create_model(img_batch, labels)\n",
        "  opt = optimizer.minimize(loss)\n",
        "  return opt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8scLrYSed0AU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here, we simulate a single batch of data just to verify that forward and backward pass run without issue."
      ]
    },
    {
      "metadata": {
        "id": "9jGb86smxLMp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Reset the graph so we don't have variable collisions when we re-run.\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# Simulate a batch of 32 images (each 32 x 32 pixels RBG)\n",
        "input_image = np.zeros((32, 32, 32, 3))\n",
        "\n",
        "# Simulate a batch of labels for the input images.\n",
        "input_labels = np.zeros((32, 10))\n",
        "for i in range(input_labels.shape[0]):\n",
        "  input_labels[i][i % 10] = 1\n",
        "\n",
        "# Create a placeholder for the input tensor (to be passed to the model).\n",
        "img = tf.placeholder(tf.float32, shape=input_image.shape)\n",
        "\n",
        "# Create a placeholder for the corresponding labels.\n",
        "img_labels = tf.placeholder(tf.float32, shape=input_labels.shape)\n",
        "\n",
        "# Create an optimizer that will manage the backpropagation.\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=1e-3)\n",
        "\n",
        "# Run a single training loop.\n",
        "trained = train_batch(img, img_labels, optimizer)\n",
        "\n",
        "# Create the TF session and run the graph.\n",
        "with tf.Session() as sess:\n",
        "  # Initialize all the variables according to their initializers.\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "\n",
        "  # This call starts the chain of operations in the computation graph created\n",
        "  # above.\n",
        "  output = sess.run(trained, feed_dict={img: input_image, img_labels: input_labels})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iw4ep02TeBSX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Bring in Data\n",
        "\n",
        "In order to actually train the model, we need to bring in actual data.  Download the CIFAR-10 dataset and get it into a format that we can use."
      ]
    },
    {
      "metadata": {
        "id": "oswKFhE1LjQQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "f410a736-caef-4cf9-c03d-c2b615f21c52"
      },
      "cell_type": "code",
      "source": [
        "# I'm cheating and using Keras to import the dataset without having to do a lot\n",
        "# of processing myself.\n",
        "from keras.datasets import cifar10\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Examine what the data looks like.\n",
        "print(\"X_train shape: {}\".format(X_train.shape))\n",
        "print(\"y_train shape: {}\".format(y_train.shape))\n",
        "print(\"X_test shape: {}\".format(X_test.shape))\n",
        "print(\"y_test shape: {}\".format(y_test.shape))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 14s 0us/step\n",
            "X_train shape: (50000, 32, 32, 3)\n",
            "y_train shape: (50000, 1)\n",
            "X_test shape: (10000, 32, 32, 3)\n",
            "y_test shape: (10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fbLmbPTafmLK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def training_loop(X, y, num_epochs=10, batch_size=128, learning_rate=1e-3):\n",
        "  \"\"\"\n",
        "  Trains a CNN on the CIFAR-10 dataset.\n",
        "  \n",
        "  Parameters:\n",
        "    - X:             The set of training samples to choose from. \n",
        "    - num_epochs:    The number of batches to process.\n",
        "    - num_samples:   The total number of samples to choose from.\n",
        "    - batch_size:    The number of samples in a training batch.\n",
        "    - learning_rate: The learning rate to use during backpropagation.\n",
        "  \"\"\"\n",
        "  num_samples = X.shape[0]\n",
        "  \n",
        "  # Reset the graph so we don't have variable collisions when we re-run.\n",
        "  tf.reset_default_graph()\n",
        "\n",
        "  # Create a placeholder for the input tensor (to be passed to the model).\n",
        "  img = tf.placeholder(tf.float32, \\\n",
        "                       shape=(batch_size, X.shape[1], X.shape[2], X.shape[3]))\n",
        "\n",
        "  # Create a placeholder for the corresponding labels.\n",
        "  img_labels = tf.placeholder(tf.float32, shape=(batch_size, y.shape[1]))\n",
        "\n",
        "  # Create an optimizer that will manage the backpropagation.\n",
        "  optimizer = tf.train.AdamOptimizer(learning_rate=1e-3)\n",
        "\n",
        "  # Run a single training loop.\n",
        "  train_op = train_batch(img, img_labels, optimizer)\n",
        "\n",
        "  # Create the TF session and run the graph.\n",
        "  with tf.Session() as sess:\n",
        "    # Initialize all the variables according to their initializers.\n",
        "    sess.run(tf.global_variables_initializer())    \n",
        "  \n",
        "    for i in range(num_epochs):\n",
        "      # Randomly select a batch of images from the training set.\n",
        "      inds = np.random.randint(0, num_samples, batch_size)\n",
        "      batch = X[inds]\n",
        "      batch_labels = y[inds]\n",
        "      \n",
        "      # This call starts the chain of operations in the computation graph created\n",
        "      # above.\n",
        "      output = sess.run(train_op, feed_dict={img: batch, img_labels: batch_labels})\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CCSUGYpZk-Cp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1544
        },
        "outputId": "038a8cf8-cce0-47e7-c593-b855a610ef01"
      },
      "cell_type": "code",
      "source": [
        "training_loop(X_train, y_train, num_epochs=5)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1627\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1628\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1629\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 128 and 32 for 'softmax/softmax_cross_entropy_with_logits' (op: 'SoftmaxCrossEntropyWithLogits') with input shapes: [128,10], [32,10].",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-92c2182e4b1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-38-824f106d53d8>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(X, y, num_epochs, batch_size, learning_rate)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0;31m# Run a single training loop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m   \u001b[0mtrained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0;31m# Create the TF session and run the graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-3c94fe606d02>\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(img_batch, labels, optimizer)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;34m-\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mTF\u001b[0m \u001b[0mOptimizer\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mperforms\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mbackpropagation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \"\"\"\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-ad3e05f6233d>\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(img_batch, classes)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;31m# dense layer into probabilities first. (The 'logits' are raw outputs of the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;31m# aforementioned outputs.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax_cross_entropy_with_logits_v2\u001b[0m\u001b[0;34m(\u001b[0m                           \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_dense3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msoftmax_cross_entropy_with_logits_v2\u001b[0;34m(_sentinel, labels, logits, dim, name)\u001b[0m\n\u001b[1;32m   1862\u001b[0m     \u001b[0;31m# _CrossEntropyGrad() in nn_grad but not here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m     cost, unused_backprop = gen_nn_ops.softmax_cross_entropy_with_logits(\n\u001b[0;32m-> 1864\u001b[0;31m         precise_logits, labels, name=name)\n\u001b[0m\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m     \u001b[0;31m# The output cost shape should be the input minus dim.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36msoftmax_cross_entropy_with_logits\u001b[0;34m(features, labels, name)\u001b[0m\n\u001b[1;32m   7208\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   7209\u001b[0m         \u001b[0;34m\"SoftmaxCrossEntropyWithLogits\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7210\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   7211\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7212\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m                 instructions)\n\u001b[0;32m--> 488\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    490\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3272\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3273\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3274\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3275\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3276\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1790\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1791\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1792\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1629\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 128 and 32 for 'softmax/softmax_cross_entropy_with_logits' (op: 'SoftmaxCrossEntropyWithLogits') with input shapes: [128,10], [32,10]."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "-BfEcbY0mYP-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}