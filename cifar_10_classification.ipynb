{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar_10_classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eswens13/deep_learning/blob/master/cifar_10_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "6z5Ar347Yyn5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CIFAR-10 Classifier/Autoencoder\n",
        "\n",
        "This notebook is an exploratory exercise in convolutional neural networks.  I will build a classifier for the CIFAR-10 image set and play around with network architecture, hyperparameters, visualization techniques, etc. to get hands-on experience coding convolutional neural networks in TensorFlow.\n",
        "\n",
        "I will also explore the differences between a classifier and an auto-encoder."
      ]
    },
    {
      "metadata": {
        "id": "adTggxluwJQT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define Network Architecture\n",
        "\n",
        "First, we have to define a network architecture.  The code in the cell below has comments explaining the architecture of each of the layers."
      ]
    },
    {
      "metadata": {
        "id": "foT4cF9uqIpv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def create_model(img_batch, classes):\n",
        "  \"\"\"\n",
        "  Defines the neural network architecture for CIFAR-10 classification.\n",
        "  \n",
        "  Parameters:\n",
        "    - img_batch: A batch of images to classify, as a Tensor object.\n",
        "                 Shape: (N x 32 x 32 x 3)\n",
        "    - classes:   The labels for each image, as a Tensor object.\n",
        "                 Shape: (N, 10)\n",
        "  \"\"\"\n",
        "  [N, H, W, C] = img_batch.get_shape().as_list()\n",
        "  \n",
        "  # Convolutional Layer 1:\n",
        "  #    - Input shape: (N, 32, 32, 3)\n",
        "  #    - 16 3x3 filters\n",
        "  #    - Zero-pad input to keep same feature map dimensions\n",
        "  #    - ReLU activation\n",
        "  #    - Output shape: (N, 32, 32, 16)\n",
        "  with tf.variable_scope(\"conv1\") as scope:\n",
        "    filter_shape_conv1 = (3, 3)\n",
        "    filters_conv1 = 16\n",
        "    w_conv1 = tf.get_variable(\"W\", \\\n",
        "                              [filter_shape_conv1[0], \\\n",
        "                                filter_shape_conv1[1], \\\n",
        "                                C, \\\n",
        "                                filters_conv1], \\\n",
        "                              initializer=tf.random_normal_initializer)\n",
        "    b_conv1 = tf.get_variable(\"b\", \\\n",
        "                              [filters_conv1], \\\n",
        "                              initializer=tf.zeros_initializer)\n",
        "    strides = [1, 1, 1, 1]\n",
        "    padding = \"SAME\"\n",
        "    \n",
        "    conv_conv1 = tf.nn.conv2d(img_batch, w_conv1, strides, padding)\n",
        "    out1 = tf.nn.relu(conv_conv1 + b_conv1, name=scope.name)\n",
        "  \n",
        "  # Convolutional Layer 2:\n",
        "  #    - Input shape: (N, 32, 32, 16)\n",
        "  #    - 32 3x3 filters\n",
        "  #    - Lose a pixel off each side because of convolution.\n",
        "  #    - ReLU activation\n",
        "  #    - Output shape: (N, 30, 30, 32)\n",
        "  with tf.variable_scope(\"conv2\") as scope:\n",
        "    filter_shape_conv2 = (3, 3)\n",
        "    filters_conv2 = 32\n",
        "    w_conv2 = tf.get_variable(\"W\", \\\n",
        "                              [filter_shape_conv2[0], \\\n",
        "                                filter_shape_conv2[1], \\\n",
        "                                filters_conv1, \\\n",
        "                                filters_conv2], \\\n",
        "                              initializer=tf.random_normal_initializer)\n",
        "    b_conv2 = tf.get_variable(\"b\", \\\n",
        "                              [filters_conv2], \\\n",
        "                              initializer=tf.zeros_initializer)\n",
        "    strides = [1, 1, 1, 1]\n",
        "    padding = \"VALID\"\n",
        "    \n",
        "    conv_conv2 = tf.nn.conv2d(out1, w_conv2, strides, padding)\n",
        "    out2 = tf.nn.relu(conv_conv2 + b_conv2, name=scope.name)\n",
        "  \n",
        "  # Convolutional Layer 3:\n",
        "  #    - Input shape: (N, 30, 30, 32)\n",
        "  #    - 64 5x5 filters\n",
        "  #    - Lose two pixels off each side because of convolution.\n",
        "  #    - ReLU activation\n",
        "  #    - Output shape: (N, 26, 26, 64)\n",
        "  with tf.variable_scope(\"conv3\") as scope:\n",
        "    filter_shape_conv3 = (5, 5)\n",
        "    filters_conv3 = 64\n",
        "    w_conv3 = tf.get_variable(\"W\", \\\n",
        "                              [filter_shape_conv3[0], \\\n",
        "                                filter_shape_conv3[1], \\\n",
        "                                filters_conv2, \\\n",
        "                                filters_conv3], \\\n",
        "                              initializer=tf.random_normal_initializer)\n",
        "    b_conv3 = tf.get_variable(\"b\", \\\n",
        "                              [filters_conv3], \\\n",
        "                              initializer=tf.zeros_initializer)\n",
        "    strides = [1, 1, 1, 1]\n",
        "    padding = \"VALID\"\n",
        "    \n",
        "    conv_conv3 = tf.nn.conv2d(out2, w_conv3, strides, padding)\n",
        "    out3 = tf.nn.relu(conv_conv3 + b_conv3, name=scope.name)\n",
        "  \n",
        "    # Since this is the last convolutional layer, we need to \"flatten\" the\n",
        "    # output into a one dimensional vector (well, really a one-dimensional\n",
        "    # vector per input image).\n",
        "    flat_out = tf.reshape(out3, [N, -1])\n",
        "    neurons_flat = flat_out.get_shape().as_list()[1]\n",
        "  \n",
        "  # Dense Layer 1:\n",
        "  #    - Input shape: (N, (26 * 26 * 64))\n",
        "  #    - Neurons: 512\n",
        "  #    - ReLU activation\n",
        "  #    - Ouput shape: (N, 512)\n",
        "  with tf.variable_scope(\"dense1\") as scope:\n",
        "    neurons_dense1 = 512\n",
        "    w_dense1 = tf.get_variable(\"W\", \\\n",
        "                               [neurons_flat, neurons_dense1], \\\n",
        "                               initializer=tf.random_normal_initializer)\n",
        "    b_dense1 = tf.get_variable(\"b\", \\\n",
        "                               [neurons_dense1], \\\n",
        "                               initializer=tf.zeros_initializer)\n",
        "    mul_dense1 = tf.matmul(flat_out, w_dense1)\n",
        "    out_dense1 = tf.nn.relu(mul_dense1 + b_dense1, name=scope.name)\n",
        "  \n",
        "  # Dense Layer 2:\n",
        "  #    - Input shape: (N, 512)\n",
        "  #    - Neurons: 128\n",
        "  #    - ReLU activation\n",
        "  #    - Ouput shape: (N, 128)\n",
        "  with tf.variable_scope(\"dense2\") as scope:\n",
        "    neurons_dense2 = 128\n",
        "    w_dense2 = tf.get_variable(\"W\", \\\n",
        "                               [neurons_dense1, neurons_dense2], \\\n",
        "                               initializer=tf.random_normal_initializer)\n",
        "    b_dense2 = tf.get_variable(\"b\", \\\n",
        "                                [neurons_dense2], \\\n",
        "                                initializer=tf.zeros_initializer)\n",
        "    mul_dense2 = tf.matmul(out_dense1, w_dense2)\n",
        "    out_dense2 = tf.nn.relu(mul_dense2 + b_dense2, name=scope.name)\n",
        "    \n",
        "  with tf.variable_scope(\"dense3\") as scope:\n",
        "    n_classes = 10\n",
        "    w_dense3 = tf.get_variable(\"W\", \\\n",
        "                               [neurons_dense2, n_classes], \\\n",
        "                               initializer=tf.random_normal_initializer)\n",
        "    b_dense3 = tf.get_variable(\"b\", \\\n",
        "                                [n_classes], \\\n",
        "                                initializer=tf.zeros_initializer)\n",
        "    mul_dense3 = tf.matmul(out_dense2, w_dense3)\n",
        "    out_dense3 = mul_dense3 + b_dense3\n",
        "  \n",
        "  # Softmax layer.\n",
        "  with tf.variable_scope(\"softmax\") as scope:\n",
        "    # The reduce_mean takes the mean in a given axis, thereby reducing the\n",
        "    # the dimensions of the tensor. If no axis is given, it takes the mean of\n",
        "    # the entire tensor.\n",
        "    #\n",
        "    # The softmax_cross_entropy_with_logits_v2 function calculates the softmax\n",
        "    # cross entropy loss without requiring us to convert the outputs of the last\n",
        "    # dense layer into probabilities first. (The 'logits' are raw outputs of the\n",
        "    # aforementioned outputs.)\n",
        "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2( \\\n",
        "                          labels=classes, logits=out_dense3))\n",
        "  \n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oYdNDESBQPqa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training Setup\n",
        "\n",
        "Now that we've defined a network architecture, we need to set up a training loop to map how the network will be updated.  We need to choose an optimizer and set up backpropagation."
      ]
    },
    {
      "metadata": {
        "id": "rU1UppagQA_n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def train_batch(img_batch, labels, optimizer):\n",
        "  \"\"\"\n",
        "  Trains the network (forward pass followed by backpropagation) on a batch of\n",
        "  images.\n",
        "  \n",
        "  Parameters:\n",
        "    - img_batch: A batch of input images, as a Tensor object.\n",
        "                 Shape: (N, H, W, C)\n",
        "    - labels:    The labels for each input image in the batch, as a Tensor.\n",
        "                 Shape: (N, 10)\n",
        "    - optimizer: A TF Optimizer object that performs the backpropagation.\n",
        "  \"\"\"\n",
        "  loss = create_model(img_batch, labels)\n",
        "  opt = optimizer.minimize(loss)\n",
        "  return loss, opt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8scLrYSed0AU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here, we simulate a single batch of data just to verify that forward and backward pass run without issue."
      ]
    },
    {
      "metadata": {
        "id": "9jGb86smxLMp",
        "colab_type": "code",
        "outputId": "e12328de-5352-4e8f-a37f-9d837a5941c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Reset the graph so we don't have variable collisions when we re-run.\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# Simulate a batch of 32 images (each 32 x 32 pixels RBG)\n",
        "input_image = np.zeros((32, 32, 32, 3))\n",
        "\n",
        "# Simulate a batch of labels for the input images.\n",
        "input_labels = np.zeros((32, 10))\n",
        "for i in range(input_labels.shape[0]):\n",
        "  input_labels[i][i % 10] = 1\n",
        "\n",
        "# Create a placeholder for the input tensor (to be passed to the model).\n",
        "img = tf.placeholder(tf.float32, shape=input_image.shape)\n",
        "\n",
        "# Create a placeholder for the corresponding labels.\n",
        "img_labels = tf.placeholder(tf.float32, shape=input_labels.shape)\n",
        "\n",
        "# Create an optimizer that will manage the backpropagation.\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=1e-3)\n",
        "\n",
        "# Run a single training loop.\n",
        "loss, backprop = train_batch(img, img_labels, optimizer)\n",
        "\n",
        "# Create the TF session and run the graph.\n",
        "with tf.Session() as sess:\n",
        "  # Initialize all the variables according to their initializers.\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "\n",
        "  # This call starts the chain of operations in the computation graph created\n",
        "  # above.\n",
        "  loss_output = sess.run(loss, feed_dict={img: input_image, \\\n",
        "                                          img_labels: input_labels})\n",
        "  \n",
        "  opt_output = sess.run(backprop, feed_dict={img: input_image, \\\n",
        "                                             img_labels: input_labels})\n",
        "  \n",
        "  print(\"Output: {}\".format(loss_output))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output: 2.3025851249694824\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iw4ep02TeBSX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Bring in Data\n",
        "\n",
        "In order to actually train the model, we need to bring in actual data.  Download the CIFAR-10 dataset and get it into a format that we can use."
      ]
    },
    {
      "metadata": {
        "id": "oswKFhE1LjQQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ad126590-8d9f-452a-925a-8472b61ff2c8"
      },
      "cell_type": "code",
      "source": [
        "# I'm cheating and using Keras to import the dataset without having to do a lot\n",
        "# of processing myself.\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Change the labels to one-hot vectors.\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# Examine what the data looks like.\n",
        "print(\"X_train shape: {}\".format(X_train.shape))\n",
        "print(\"y_train shape: {}\".format(y_train.shape))\n",
        "print(\"X_test shape: {}\".format(X_test.shape))\n",
        "print(\"y_test shape: {}\".format(y_test.shape))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape: (50000, 32, 32, 3)\n",
            "y_train shape: (50000, 10)\n",
            "X_test shape: (10000, 32, 32, 3)\n",
            "y_test shape: (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fbLmbPTafmLK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def training_loop(X, y, num_epochs=10, batch_size=128, learning_rate=1e-3):\n",
        "  \"\"\"\n",
        "  Trains a CNN on the CIFAR-10 dataset.\n",
        "  \n",
        "  Parameters:\n",
        "    - X:             The set of training samples to choose from. \n",
        "    - num_epochs:    The number of batches to process.\n",
        "    - num_samples:   The total number of samples to choose from.\n",
        "    - batch_size:    The number of samples in a training batch.\n",
        "    - learning_rate: The learning rate to use during backpropagation.\n",
        "  \"\"\"\n",
        "  num_samples = X.shape[0]\n",
        "  \n",
        "  # Reset the graph so we don't have variable collisions when we re-run.\n",
        "  tf.reset_default_graph()\n",
        "\n",
        "  # Create a placeholder for the input tensor (to be passed to the model).\n",
        "  img = tf.placeholder(tf.float32, \\\n",
        "                       shape=(batch_size, X.shape[1], X.shape[2], X.shape[3]))\n",
        "\n",
        "  # Create a placeholder for the corresponding labels.\n",
        "  img_labels = tf.placeholder(tf.float32, shape=(batch_size, y.shape[1]))\n",
        "\n",
        "  # Create an optimizer that will manage the backpropagation.\n",
        "  optimizer = tf.train.AdamOptimizer(learning_rate=1e-3)\n",
        "\n",
        "  # Run a single training loop.\n",
        "  loss, backprop = train_batch(img, img_labels, optimizer)\n",
        "  \n",
        "  # Create a vector for the losses from each epoch.\n",
        "  loss_history = []\n",
        "\n",
        "  # Create the TF session and run the graph.\n",
        "  with tf.Session() as sess:\n",
        "    # Initialize all the variables according to their initializers.\n",
        "    sess.run(tf.global_variables_initializer())    \n",
        "  \n",
        "    for i in range(num_epochs):\n",
        "      # Randomly select a batch of images from the training set.\n",
        "      inds = np.random.randint(0, num_samples, batch_size)\n",
        "      batch = X[inds]\n",
        "      batch_labels = y[inds]\n",
        "      \n",
        "      # Get the loss using the current weights in the graph. This call starts\n",
        "      # the chain of operations in the computation graph created above.\n",
        "      epoch_loss = sess.run(loss, feed_dict={img: batch, \\\n",
        "                                             img_labels: batch_labels})\n",
        "      \n",
        "      # Run backpropagation on the graph.\n",
        "      sess.run(backprop, feed_dict={img: batch, img_labels: batch_labels})\n",
        "      \n",
        "      # Keep track of the loss.\n",
        "      loss_history.append(epoch_loss)\n",
        "\n",
        "  # Plot the loss over the whole training episode.\n",
        "  font_dict = { 'fontweight' : 'bold' }\n",
        "  plt.title(\"Training Loss\", fontdict=font_dict)\n",
        "  plt.plot(loss_history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GGsrpneaF7Gb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Run Training\n",
        "\n",
        "Run the training loop for 100 batches of images (happens fairly fast) and investigate the effectiveness of the network."
      ]
    },
    {
      "metadata": {
        "id": "CCSUGYpZk-Cp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "9ed59223-e3e3-4d51-bd00-a2cf695037a3"
      },
      "cell_type": "code",
      "source": [
        "training_loop(X_train, y_train, num_epochs=100)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fd3ab5f3160>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Ky7MjyB3H9s5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Validate the Network\n",
        "\n",
        "Run the network against the validation data set to evaluate the classification effectiveness."
      ]
    },
    {
      "metadata": {
        "id": "BBVXlbJqIGoZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}