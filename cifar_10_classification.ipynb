{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar_10_classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eswens13/deep_learning/blob/master/cifar_10_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "6z5Ar347Yyn5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CIFAR-10 Classifier/Autoencoder\n",
        "\n",
        "This notebook is an exploratory exercise in convolutional neural networks.  I will build a classifier for the CIFAR-10 image set and play around with network architecture, hyperparameters, visualization techniques, etc. to get hands-on experience coding convolutional neural networks in TensorFlow.\n",
        "\n",
        "I will also explore the differences between a classifier and an auto-encoder."
      ]
    },
    {
      "metadata": {
        "id": "adTggxluwJQT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define Network Architecture\n",
        "\n",
        "First, we have to define a network architecture.  The code in the cell below has comments explaining the architecture of each of the layers."
      ]
    },
    {
      "metadata": {
        "id": "foT4cF9uqIpv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def create_model(input_image):\n",
        "  \"\"\"\n",
        "  Defines the neural network architecture for CIFAR-10 classification.\n",
        "  \n",
        "  Parameters:\n",
        "    input_image - The image to classify. Shape: (N x 32 x 32 x 3)\n",
        "  \"\"\"\n",
        "  input_shape = input_image.shape\n",
        "  (N, H, W, C) = input_shape\n",
        "  \n",
        "  # Convolutional Layer 1:\n",
        "  #    - Input shape: (N, 32, 32, 3)\n",
        "  #    - 16 3x3 filters\n",
        "  #    - Zero-pad input to keep same feature map dimensions\n",
        "  #    - ReLU activation\n",
        "  #    - Output shape: (N, 32, 32, 16)\n",
        "  with tf.variable_scope(\"conv1\") as scope:\n",
        "    filter_shape_conv1 = (3, 3)\n",
        "    filters_conv1 = 16\n",
        "    img = tf.placeholder(tf.float32, shape=input_shape)\n",
        "    w_conv1 = tf.get_variable(\"W\", \\\n",
        "                              [filter_shape_conv1[0], \\\n",
        "                                filter_shape_conv1[1], \\\n",
        "                                C, \\\n",
        "                                filters_conv1], \\\n",
        "                              initializer=tf.random_normal_initializer)\n",
        "    b_conv1 = tf.get_variable(\"b\", \\\n",
        "                              [filters_conv1], \\\n",
        "                              initializer=tf.zeros_initializer)\n",
        "    strides = [1, 1, 1, 1]\n",
        "    padding = \"SAME\"\n",
        "    \n",
        "    conv_conv1 = tf.nn.conv2d(img, w_conv1, strides, padding)\n",
        "    out1 = tf.nn.relu(conv_conv1 + b_conv1, name=scope.name)\n",
        "  \n",
        "  # Convolutional Layer 2:\n",
        "  #    - Input shape: (N, 32, 32, 16)\n",
        "  #    - 32 3x3 filters\n",
        "  #    - Lose a pixel off each side because of convolution.\n",
        "  #    - ReLU activation\n",
        "  #    - Output shape: (N, 30, 30, 32)\n",
        "  with tf.variable_scope(\"conv2\") as scope:\n",
        "    filter_shape_conv2 = (3, 3)\n",
        "    filters_conv2 = 32\n",
        "    w_conv2 = tf.get_variable(\"W\", \\\n",
        "                              [filter_shape_conv2[0], \\\n",
        "                                filter_shape_conv2[1], \\\n",
        "                                filters_conv1, \\\n",
        "                                filters_conv2], \\\n",
        "                              initializer=tf.random_normal_initializer)\n",
        "    b_conv2 = tf.get_variable(\"b\", \\\n",
        "                              [filters_conv2], \\\n",
        "                              initializer=tf.zeros_initializer)\n",
        "    strides = [1, 1, 1, 1]\n",
        "    padding = \"VALID\"\n",
        "    \n",
        "    conv_conv2 = tf.nn.conv2d(out1, w_conv2, strides, padding)\n",
        "    out2 = tf.nn.relu(conv_conv2 + b_conv2, name=scope.name)\n",
        "  \n",
        "  # Convolutional Layer 3:\n",
        "  #    - Input shape: (N, 30, 30, 32)\n",
        "  #    - 64 5x5 filters\n",
        "  #    - Lose two pixels off each side because of convolution.\n",
        "  #    - ReLU activation\n",
        "  #    - Output shape: (N, 26, 26, 64)\n",
        "  with tf.variable_scope(\"conv3\") as scope:\n",
        "    filter_shape_conv3 = (5, 5)\n",
        "    filters_conv3 = 64\n",
        "    w_conv3 = tf.get_variable(\"W\", \\\n",
        "                              [filter_shape_conv3[0], \\\n",
        "                                filter_shape_conv3[1], \\\n",
        "                                filters_conv2, \\\n",
        "                                filters_conv3], \\\n",
        "                              initializer=tf.random_normal_initializer)\n",
        "    b_conv3 = tf.get_variable(\"b\", \\\n",
        "                              [filters_conv3], \\\n",
        "                              initializer=tf.zeros_initializer)\n",
        "    strides = [1, 1, 1, 1]\n",
        "    padding = \"VALID\"\n",
        "    \n",
        "    conv_conv3 = tf.nn.conv2d(out2, w_conv3, strides, padding)\n",
        "    out3 = tf.nn.relu(conv_conv3 + b_conv3, name=scope.name)\n",
        "  \n",
        "  # Create the TF session and run the graph.\n",
        "  with tf.Session() as sess:\n",
        "    # Initialize all the variables according to their initializers.\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "    # This call starts the chain of operations in the computation graph created\n",
        "    # above.\n",
        "    output = sess.run(out3, feed_dict={img: input_image})\n",
        "    print(\"Output Shape: {}\".format(output.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9jGb86smxLMp",
        "colab_type": "code",
        "outputId": "de4fcc0a-b6ce-4b30-9cd3-b7e190cadaf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Reset the graph so we don't have variable collisions when we re-run.\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# Simulate a batch of 32 images (each 32 x 32 pixels RBG)\n",
        "input_image = np.zeros((32, 32, 32, 3))\n",
        "create_model(input_image)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output Shape: (32, 26, 26, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}